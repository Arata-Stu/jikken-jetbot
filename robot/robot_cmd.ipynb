{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../train')\n",
    "\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import traitlets\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import threading\n",
    "\n",
    "from learn import SimpleCNN,SimpleCNN_1,CustomResNet,CustomCircleDataset\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_width = 224\n",
    "widget_height = 224\n",
    "\n",
    "camera_widget = widgets.Image(format='jpg', width=widget_width, height=widget_height)\n",
    "target_widget = widgets.Image(format='jpg', width=widget_width, height=widget_height)\n",
    "image_layout = widgets.HBox([camera_widget, target_widget])\n",
    "\n",
    "#mask slider\n",
    "low_h_slider = widgets.IntSlider(description='low h', min=0, max=179, value=90,step=1)\n",
    "high_h_slider = widgets.IntSlider(description=' high h', min=0, max=179, value=100,step=1)\n",
    "low_s_slider = widgets.IntSlider(description=' low s', min=0, max=255, value=140,step=1)\n",
    "high_s_slider = widgets.IntSlider(description=' high s', min=0, max=255, value=255,step=1)\n",
    "low_v_slider = widgets.IntSlider(description=' low v', min=0, max=255, value=0,step=1)\n",
    "high_v_slider = widgets.IntSlider(description=' high v', min=0, max=255, value=255,step=1)\n",
    "\n",
    "h_slider = widgets.HBox([low_h_slider, high_h_slider])\n",
    "s_slider = widgets.HBox([low_s_slider, high_s_slider])\n",
    "v_slider = widgets.HBox([low_v_slider, high_v_slider])\n",
    "slider = widgets.VBox([h_slider,s_slider,v_slider])\n",
    "\n",
    "#robot param slider\n",
    "far_slider = widgets.IntSlider(description='far rad', min=0, max=100, value=20,step=1)\n",
    "near_slider = widgets.IntSlider(description=' near rad', min=0, max=100, value=30,step=1)\n",
    "speed_slider = widgets.FloatSlider(description='speed', min=0, max=1.0, value=0,step=0.1)\n",
    "interval_slider = widgets.FloatSlider(description=' interval', min=0, max=5.0, value=0.5,step=0.1)\n",
    "robot_slider = widgets.VBox([far_slider, near_slider, speed_slider, interval_slider])\n",
    "\n",
    "layout = widgets.Layout(width='128px', height='64px')\n",
    "snap_button = widgets.Button(description='snapshot', button_style='success', layout=layout)\n",
    "percent = widgets.IntText(layout = layout,value = 0)\n",
    "gui_layout =  widgets.HBox([image_layout,percent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバイスの設定（CUDAが利用可能な場合はGPUを使用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# モデルのインスタンスを作成\n",
    "model = SimpleCNN()\n",
    "# モデルの重みをロードし、推論モードに設定\n",
    "model.load_state_dict(torch.load('weight/model_2.pth'))\n",
    "model.to(device)  # モデルをGPUに移動\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(image,model,device):\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    img_tonsor = transform(pil_image).unsqueeze(0).to(device)  # テンソルをGPUに移動\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            outputs = model(img_tonsor)\n",
    "            predicted_coords = outputs.cpu().numpy()[0]  # 結果をCPUに戻す\n",
    "            pos_x, pos_y, pos_r = predicted_coords\n",
    "            return pos_x, pos_y, pos_r\n",
    "        \n",
    "\n",
    "#マスク処理する関数\n",
    "def apply_hsv_threshold(image):\n",
    "#     low_h, high_h = 91, 103  # Example range for yellow hue\n",
    "#     low_s, high_s = 200, 255 # Example range for saturation\n",
    "#     low_v, high_v = 140, 255 # Example range for value\n",
    "    low_h, high_h = low_h_slider.value, high_h_slider.value\n",
    "    low_s, high_s = low_s_slider.value, high_s_slider.value\n",
    "    low_v, high_v = low_v_slider.value, high_v_slider.value\n",
    "\n",
    "    # Convert the image from RGB to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Define the lower and upper bounds of the HSV threshold\n",
    "    lower_bound = np.array([low_h, low_s, low_v])\n",
    "    upper_bound = np.array([high_h, high_s, high_v])\n",
    "    \n",
    "    # Create a mask where pixels within the threshold are white, and others are black\n",
    "    mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    \n",
    "    # Create an all black image\n",
    "    black_image = np.zeros_like(image)\n",
    "    \n",
    "    # Copy the pixels from the original image where the mask is white\n",
    "    result_image = np.where(mask[:, :, None] == 255, image, black_image)\n",
    "    \n",
    "    return result_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カメラ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera.instance()\n",
    "#画像処理後のデータ\n",
    "img_with_circle = traitlets.Any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_processing_thread():\n",
    "    while True:\n",
    "        frame = camera.value\n",
    "        # 画像処理ロジック\n",
    "        processed_frame = apply_hsv_threshold(frame)\n",
    "        processed_image = processed_frame  # 処理後の映像を更新\n",
    "        # モデルを使用して予測\n",
    "        global model,device\n",
    "        x, y, r = model_input(processed_image,model,device)\n",
    "        x = int(x * processed_image.shape[1])\n",
    "        y = int(y * processed_image.shape[0])\n",
    "        r = int(r * (processed_image.shape[1] * 1.414))\n",
    "        \n",
    "        if pos_r < 0:\n",
    "            pos_r = 0\n",
    "            \n",
    "        global img_with_circle\n",
    "        img_with_circle = cv2.circle(processed_image, (x, y), r, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "traitlets.dlink((img_with_circle, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
