{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "balanced-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from ipywidgets import HTML\n",
    "from IPython.display import display\n",
    "import threading\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# Camera and Motor Interface for JetBot\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chemical-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "\n",
    "widget_width = 224\n",
    "widget_height = 224\n",
    "\n",
    "camera_widget = widgets.Image(format='jpg', width=widget_width, height=widget_height)\n",
    "target_widget = widgets.Image(format='jpg', width=widget_width, height=widget_height)\n",
    "image_layout = widgets.HBox([camera_widget, target_widget])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controversial-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_h_slider = widgets.IntSlider(description='low h', min=0, max=179, value=90,step=1)\n",
    "high_h_slider = widgets.IntSlider(description=' high h', min=0, max=179, value=100,step=1)\n",
    "low_s_slider = widgets.IntSlider(description=' low s', min=0, max=255, value=140,step=1)\n",
    "high_s_slider = widgets.IntSlider(description=' high s', min=0, max=255, value=255,step=1)\n",
    "low_v_slider = widgets.IntSlider(description=' low v', min=0, max=255, value=0,step=1)\n",
    "high_v_slider = widgets.IntSlider(description=' high v', min=0, max=255, value=255,step=1)\n",
    "\n",
    "h_slider = widgets.HBox([low_h_slider, high_h_slider])\n",
    "s_slider = widgets.HBox([low_s_slider, high_s_slider])\n",
    "v_slider = widgets.HBox([low_v_slider, high_v_slider])\n",
    "slider = widgets.VBox([h_slider,s_slider,v_slider])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "refined-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = widgets.Layout(width='128px', height='64px')\n",
    "snap_button = widgets.Button(description='snapshot', button_style='success', layout=layout)\n",
    "percent = widgets.IntText(layout = layout,value = 0)\n",
    "gui_layout =  widgets.HBox([image_layout,percent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "structured-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=2, padding=1)\n",
    "        # 以下の数値は計算に基づいて適切に設定してください\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)  # 56は上記の計算から得られる値\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # フラット化\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parliamentary-burner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=100352, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m# デバイスの設定（CUDAが利用可能な場合はGPUを使用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# モデルのインスタンスを作成\n",
    "model = SimpleCNN()\n",
    "\n",
    "# モデルの重みをロードし、推論モードに設定\n",
    "model.load_state_dict(torch.load('train/model_best.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cosmetic-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "dir_path = ''\n",
    "\n",
    "def save_snapshot(change):\n",
    "    global i\n",
    "    image_path = dir_path + 'sample' + str(i) + '.jpg'\n",
    "    i += 1\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(target_widget.value)\n",
    "\n",
    "snap_button.on_click(save_snapshot)\n",
    "        \n",
    "def apply_hsv_threshold(image):\n",
    "#     low_h, high_h = 91, 103  # Example range for yellow hue\n",
    "#     low_s, high_s = 200, 255 # Example range for saturation\n",
    "#     low_v, high_v = 140, 255 # Example range for value\n",
    "    low_h, high_h = low_h_slider.value, high_h_slider.value\n",
    "    low_s, high_s = low_s_slider.value, high_s_slider.value\n",
    "    low_v, high_v = low_v_slider.value, high_v_slider.value\n",
    "\n",
    "    # Convert the image from RGB to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Define the lower and upper bounds of the HSV threshold\n",
    "    lower_bound = np.array([low_h, low_s, low_v])\n",
    "    upper_bound = np.array([high_h, high_s, high_v])\n",
    "    \n",
    "    # Create a mask where pixels within the threshold are white, and others are black\n",
    "    mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "    \n",
    "    # Create an all black image\n",
    "    black_image = np.zeros_like(image)\n",
    "    \n",
    "    # Copy the pixels from the original image where the mask is white\n",
    "    result_image = np.where(mask[:, :, None] == 255, image, black_image)\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "def calibration(image):\n",
    "    # カメラ行列と歪み係数を設定（キャリブレーションプロセスから取得）\n",
    "    camera_matrix = np.array([[108.16614089 ,  0 ,        111.55104361],\n",
    "                            [  0,         143.70743912 ,121.87531702],\n",
    "                            [  0,           0,           1,        ]])\n",
    "    distortion_coefficients = np.array([-0.33140309 , 0.12007599, -0.00293275,  0.00091844 ,-0.02038985])\n",
    "\n",
    "    # 補正したい画像を読み込む\n",
    "    undistorted_image = cv2.undistort(image, camera_matrix, distortion_coefficients)\n",
    "    \n",
    "    return undistorted_image\n",
    "\n",
    "def calculate_yellow_percentage(image):\n",
    "    \n",
    "    # マスク画像内の白いピクセル（黄色いピクセルに相当）の数を数える\n",
    "    yellow_pixels = np.count_nonzero(image)\n",
    "\n",
    "    # 画像内の全ピクセルの数\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "\n",
    "    # 黄色いピクセルの割合を計算\n",
    "    yellow_percentage = (yellow_pixels / total_pixels) * 100\n",
    "\n",
    "    return yellow_percentage\n",
    "\n",
    "def display_xy(camera_image):\n",
    "    image = np.copy(camera_image)\n",
    "    image = calibration(image)\n",
    "    image = apply_hsv_threshold(image)\n",
    "    \n",
    "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    image = transform(pil_image).unsqueeze(0).to(device)\n",
    "\n",
    "    # モデルを使用して予測\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        predicted_coords = outputs.cpu().numpy()[0]\n",
    "        pos_x, pos_y, pos_r = predicted_coords\n",
    "\n",
    "    # 座標と半径をスケーリング\n",
    "    pos_x = int(pos_x * camera_image.shape[1])\n",
    "    pos_y = int(pos_y * camera_image.shape[0])\n",
    "    pos_r = int(pos_r * (camera_image.shape[1] * 1.414))\n",
    "    if pos_r < 0:\n",
    "        pos_r = 0\n",
    "\n",
    "    img = np.copy(camera_image)\n",
    "    img = apply_hsv_threshold(img)\n",
    "    # percent.value = calculate_yellow_percentage(img)  # 必要に応じて実装\n",
    "\n",
    "    img = cv2.circle(img, (pos_x, pos_y), pos_r, (0, 255, 0), 2)\n",
    "    jpeg_image = bgr8_to_jpeg(img)\n",
    "\n",
    "    return jpeg_image\n",
    "\n",
    "traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "traitlets.dlink((camera, 'value'), (target_widget, 'value'), transform=display_xy)\n",
    "snap_button.on_click(save_snapshot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regulation-swiss",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3321ef44db84a2c9a718f17f2998cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e420b52a374837be944634dedf35de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=90, description='low h', max=179), IntSlider(value=100, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275b8364ac8d44248407e2df2fe5f18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='snapshot', layout=Layout(height='64px', width='128px'), style=Butt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(image_layout)\n",
    "display(slider)\n",
    "display(snap_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-dispatch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-shaft",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
